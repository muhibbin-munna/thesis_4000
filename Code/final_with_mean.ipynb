{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sklearn.feature_selection import mutual_info_classif as MIC\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "from sklearn.externals import six\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import _name_estimators\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number = int(get_ipython().user_ns['param'])\n",
    "number = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_acc=[]\n",
    "model_precision=[]\n",
    "model_recal=[]\n",
    "model_f1=[]\n",
    "model_nam=[]\n",
    "model_confusion=[]\n",
    "model_time=[]\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report,f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Dataset CSV/csv_result-data'+str(number)+' Sampled Scenarios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the operation to create the new feature\n",
    "df['R1-VCM1'] = (df['R1-PM1:V'] - df['R1-PM7:V']) / (df['R1-PM4:I'] - df['R1-PM10:I'])\n",
    "df['R3-sV1'] = np.sin(df['R3-PA1:VH'] - df['R3-PA7:VH'])\n",
    "df['R3-sV3'] = np.sin(df['R3-PA3:VH'] - df['R3-PA9:VH'])\n",
    "# df['R2-VCM2'] = (df['R2-PM2:V'] - df['R2-PM8:V']) / (df['R2-PM5:I'] - df['R2-PM11:I'])\n",
    "df['R2-VCM1'] = (df['R2-PM1:V'] - df['R2-PM7:V']) / (df['R2-PM4:I'] - df['R2-PM10:I'])\n",
    "df['R3-VCM1'] = (df['R3-PM1:V'] - df['R3-PM7:V']) / (df['R3-PM4:I'] - df['R3-PM10:I'])\n",
    "df['R4-sI1'] = np.sin(df['R4-PA4:IH'] - df['R4-PA10:IH'])\n",
    "df['R2-VCA4'] = df['R2-PA7:VH'] - df['R2-PA10:IH']\n",
    "df['R1-sI1'] = np.sin(df['R1-PA4:IH'] - df['R1-PA10:IH'])\n",
    "df['R4-VCM2'] = (df['R4-PM2:V'] - df['R4-PM8:V']) / (df['R4-PM5:I'] - df['R4-PM11:I'])\n",
    "df['R2-VCA1'] = np.sin(df['R2-PA1:VH'] - df['R2-PA4:IH'] - df['R2-PA7:VH'] - df['R2-PA10:IH'])\n",
    "df['R3-VCM2'] = (df['R3-PM2:V'] - df['R3-PM8:V']) / (df['R3-PM5:I'] - df['R3-PM11:I'])\n",
    "df['R1-VCA4'] = df['R1-PA7:VH'] - df['R1-PA10:IH']\n",
    "df['R1-VCM2'] = (df['R1-PM2:V'] - df['R1-PM8:V']) / (df['R1-PM5:I'] - df['R1-PM11:I'])\n",
    "df['R2-VCM2'] = (df['R2-PM2:V'] - df['R2-PM8:V']) / (df['R2-PM5:I'] - df['R2-PM11:I'])\n",
    "df['R4-VCA4'] = df['R4-PA7:VH'] - df['R4-PA10:IH']\n",
    "df['R4-VCM1'] = (df['R4-PM1:V'] - df['R4-PM7:V']) / (df['R4-PM4:I'] - df['R4-PM10:I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the marker to the last of the list\n",
    "cols = list(df.columns)\n",
    "cols.remove('marker')\n",
    "df = df[cols + ['marker']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3209"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace= True)\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(value=df.mean())\n",
    "# df = df.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print(df.isin([np.inf, -np.inf]).sum().sum(), df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_z_scaled = df.copy()\n",
    "for column in df_z_scaled.columns:\n",
    "#     print(df_z_scaled[column])\n",
    "    if (df_z_scaled[column].std() != 0) and (column != 'id') and (column != 'marker'):\n",
    "        df_z_scaled[column] = (df_z_scaled[column] -\n",
    "                           df_z_scaled[column].mean()) / df_z_scaled[column].std()     \n",
    "# print(df_z_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_z_scaled.iloc[:,1:-1]\n",
    "y = df_z_scaled.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the top 31 features\n",
    "top_n_feature_names = ['R1-PM5:I', 'R1-VCM1', 'R3-PM5:I', 'R1-PA1:VH', 'R4-PA2:VH', 'R3-sV3',\n",
    " 'R1-PA3:VH', 'R2-VCM1', 'R4-VCM1', 'R3-PA5:IH', 'R1-PA2:VH', 'R3-sV1',\n",
    " 'R2-PA5:IH', 'R2-PA3:VH', 'R2-PA6:IH', 'R2-PA1:VH', 'R3-VCM1', 'R4-PA5:IH',\n",
    " 'R2-VCA4', 'R3-PA6:IH', 'R4-PM2:V', 'R2-PA4:IH', 'R3-PA4:IH', 'R1-PA5:IH',\n",
    " 'R1-sI1', 'R2-PA2:VH', 'R1-PM2:V', 'R3-PA:ZH', 'R2-VCM2', 'R1-VCM2', 'R4-VCM2']\n",
    "\n",
    "# Filter the original dataframe to only include the top n features\n",
    "X_top_n = X[top_n_feature_names].copy()\n",
    "\n",
    "X_new = X_top_n.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R1-PM5:I</th>\n",
       "      <th>R1-VCM1</th>\n",
       "      <th>R3-PM5:I</th>\n",
       "      <th>R1-PA1:VH</th>\n",
       "      <th>R4-PA2:VH</th>\n",
       "      <th>R3-sV3</th>\n",
       "      <th>R1-PA3:VH</th>\n",
       "      <th>R2-VCM1</th>\n",
       "      <th>R4-VCM1</th>\n",
       "      <th>R3-PA5:IH</th>\n",
       "      <th>...</th>\n",
       "      <th>R2-PA4:IH</th>\n",
       "      <th>R3-PA4:IH</th>\n",
       "      <th>R1-PA5:IH</th>\n",
       "      <th>R1-sI1</th>\n",
       "      <th>R2-PA2:VH</th>\n",
       "      <th>R1-PM2:V</th>\n",
       "      <th>R3-PA:ZH</th>\n",
       "      <th>R2-VCM2</th>\n",
       "      <th>R1-VCM2</th>\n",
       "      <th>R4-VCM2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.627657</td>\n",
       "      <td>0.032498</td>\n",
       "      <td>0.593858</td>\n",
       "      <td>0.280064</td>\n",
       "      <td>-1.237048</td>\n",
       "      <td>-1.315449</td>\n",
       "      <td>1.213908</td>\n",
       "      <td>0.028357</td>\n",
       "      <td>-0.014322</td>\n",
       "      <td>0.632234</td>\n",
       "      <td>...</td>\n",
       "      <td>1.636321</td>\n",
       "      <td>1.636498</td>\n",
       "      <td>-1.307082</td>\n",
       "      <td>1.382465</td>\n",
       "      <td>-1.318864</td>\n",
       "      <td>-0.212841</td>\n",
       "      <td>2.724037</td>\n",
       "      <td>-0.124961</td>\n",
       "      <td>-0.055162</td>\n",
       "      <td>-0.027867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.777983</td>\n",
       "      <td>0.063392</td>\n",
       "      <td>0.741773</td>\n",
       "      <td>0.264425</td>\n",
       "      <td>-1.251975</td>\n",
       "      <td>0.989595</td>\n",
       "      <td>1.196701</td>\n",
       "      <td>0.025628</td>\n",
       "      <td>-0.089056</td>\n",
       "      <td>0.611412</td>\n",
       "      <td>...</td>\n",
       "      <td>1.602650</td>\n",
       "      <td>1.602326</td>\n",
       "      <td>-1.328207</td>\n",
       "      <td>0.727325</td>\n",
       "      <td>-1.336730</td>\n",
       "      <td>-0.140439</td>\n",
       "      <td>-0.446013</td>\n",
       "      <td>-0.145185</td>\n",
       "      <td>-0.065000</td>\n",
       "      <td>-0.029703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.775558</td>\n",
       "      <td>0.032498</td>\n",
       "      <td>0.739406</td>\n",
       "      <td>0.263535</td>\n",
       "      <td>-1.252769</td>\n",
       "      <td>1.045699</td>\n",
       "      <td>1.195905</td>\n",
       "      <td>0.014827</td>\n",
       "      <td>-0.054766</td>\n",
       "      <td>0.610133</td>\n",
       "      <td>...</td>\n",
       "      <td>1.598915</td>\n",
       "      <td>1.600499</td>\n",
       "      <td>-1.328912</td>\n",
       "      <td>0.617168</td>\n",
       "      <td>-1.337346</td>\n",
       "      <td>-0.119145</td>\n",
       "      <td>-0.445742</td>\n",
       "      <td>-0.145577</td>\n",
       "      <td>-0.065091</td>\n",
       "      <td>-0.029708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.770709</td>\n",
       "      <td>0.032498</td>\n",
       "      <td>0.731123</td>\n",
       "      <td>0.262589</td>\n",
       "      <td>-1.253669</td>\n",
       "      <td>1.123263</td>\n",
       "      <td>1.194741</td>\n",
       "      <td>0.008040</td>\n",
       "      <td>-0.153825</td>\n",
       "      <td>0.609098</td>\n",
       "      <td>...</td>\n",
       "      <td>1.591954</td>\n",
       "      <td>1.593194</td>\n",
       "      <td>-1.330482</td>\n",
       "      <td>0.417324</td>\n",
       "      <td>-1.337962</td>\n",
       "      <td>-0.072297</td>\n",
       "      <td>-0.437863</td>\n",
       "      <td>-0.145104</td>\n",
       "      <td>-0.065039</td>\n",
       "      <td>-0.029698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.771921</td>\n",
       "      <td>0.032498</td>\n",
       "      <td>0.729940</td>\n",
       "      <td>0.261698</td>\n",
       "      <td>-1.254675</td>\n",
       "      <td>1.188072</td>\n",
       "      <td>1.193639</td>\n",
       "      <td>0.009062</td>\n",
       "      <td>-0.177378</td>\n",
       "      <td>0.607333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.587201</td>\n",
       "      <td>1.589305</td>\n",
       "      <td>-1.331999</td>\n",
       "      <td>0.218662</td>\n",
       "      <td>-1.338732</td>\n",
       "      <td>-0.051002</td>\n",
       "      <td>-0.436334</td>\n",
       "      <td>-0.145753</td>\n",
       "      <td>-0.065393</td>\n",
       "      <td>-0.029765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>-0.679210</td>\n",
       "      <td>0.032498</td>\n",
       "      <td>-0.564608</td>\n",
       "      <td>1.445745</td>\n",
       "      <td>-0.126369</td>\n",
       "      <td>-0.462768</td>\n",
       "      <td>-1.350914</td>\n",
       "      <td>0.030555</td>\n",
       "      <td>-0.013022</td>\n",
       "      <td>1.924613</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.815532</td>\n",
       "      <td>-0.854336</td>\n",
       "      <td>-0.072547</td>\n",
       "      <td>1.631611</td>\n",
       "      <td>-0.169837</td>\n",
       "      <td>0.106578</td>\n",
       "      <td>-0.430800</td>\n",
       "      <td>0.159554</td>\n",
       "      <td>0.080392</td>\n",
       "      <td>-0.005228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5198</th>\n",
       "      <td>-0.671936</td>\n",
       "      <td>0.032498</td>\n",
       "      <td>-0.572891</td>\n",
       "      <td>1.444799</td>\n",
       "      <td>-0.127534</td>\n",
       "      <td>-0.614585</td>\n",
       "      <td>-1.351955</td>\n",
       "      <td>0.019059</td>\n",
       "      <td>-0.013022</td>\n",
       "      <td>1.925709</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.822040</td>\n",
       "      <td>-0.854454</td>\n",
       "      <td>-0.078722</td>\n",
       "      <td>1.623928</td>\n",
       "      <td>-0.170967</td>\n",
       "      <td>0.110836</td>\n",
       "      <td>-0.431232</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>0.078757</td>\n",
       "      <td>-0.005356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5199</th>\n",
       "      <td>-0.617382</td>\n",
       "      <td>0.032498</td>\n",
       "      <td>-0.584724</td>\n",
       "      <td>1.441515</td>\n",
       "      <td>-0.131663</td>\n",
       "      <td>-1.055520</td>\n",
       "      <td>-1.355568</td>\n",
       "      <td>0.016193</td>\n",
       "      <td>-0.061298</td>\n",
       "      <td>1.924369</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.849712</td>\n",
       "      <td>-0.855868</td>\n",
       "      <td>-0.106022</td>\n",
       "      <td>1.347340</td>\n",
       "      <td>-0.174612</td>\n",
       "      <td>0.153426</td>\n",
       "      <td>-0.427190</td>\n",
       "      <td>0.126257</td>\n",
       "      <td>0.067752</td>\n",
       "      <td>-0.005694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>-0.568890</td>\n",
       "      <td>0.032498</td>\n",
       "      <td>-0.569341</td>\n",
       "      <td>1.438009</td>\n",
       "      <td>-0.135421</td>\n",
       "      <td>-1.348203</td>\n",
       "      <td>-1.359425</td>\n",
       "      <td>-0.032542</td>\n",
       "      <td>-0.283365</td>\n",
       "      <td>1.909331</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.875573</td>\n",
       "      <td>-0.870125</td>\n",
       "      <td>-0.130614</td>\n",
       "      <td>0.341028</td>\n",
       "      <td>-0.178257</td>\n",
       "      <td>0.183238</td>\n",
       "      <td>-0.409488</td>\n",
       "      <td>0.103326</td>\n",
       "      <td>0.054063</td>\n",
       "      <td>-0.007536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5201</th>\n",
       "      <td>-0.566465</td>\n",
       "      <td>0.032498</td>\n",
       "      <td>-0.566974</td>\n",
       "      <td>1.437619</td>\n",
       "      <td>-0.135844</td>\n",
       "      <td>-1.367497</td>\n",
       "      <td>-1.359854</td>\n",
       "      <td>-0.036711</td>\n",
       "      <td>-0.283365</td>\n",
       "      <td>1.907444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.876988</td>\n",
       "      <td>-0.871363</td>\n",
       "      <td>-0.131373</td>\n",
       "      <td>0.296863</td>\n",
       "      <td>-0.178616</td>\n",
       "      <td>0.183238</td>\n",
       "      <td>-0.407941</td>\n",
       "      <td>0.097264</td>\n",
       "      <td>0.053705</td>\n",
       "      <td>-0.007525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5202 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      R1-PM5:I   R1-VCM1  R3-PM5:I  R1-PA1:VH  R4-PA2:VH    R3-sV3  R1-PA3:VH  \\\n",
       "0     0.627657  0.032498  0.593858   0.280064  -1.237048 -1.315449   1.213908   \n",
       "1     0.777983  0.063392  0.741773   0.264425  -1.251975  0.989595   1.196701   \n",
       "2     0.775558  0.032498  0.739406   0.263535  -1.252769  1.045699   1.195905   \n",
       "3     0.770709  0.032498  0.731123   0.262589  -1.253669  1.123263   1.194741   \n",
       "4     0.771921  0.032498  0.729940   0.261698  -1.254675  1.188072   1.193639   \n",
       "...        ...       ...       ...        ...        ...       ...        ...   \n",
       "5197 -0.679210  0.032498 -0.564608   1.445745  -0.126369 -0.462768  -1.350914   \n",
       "5198 -0.671936  0.032498 -0.572891   1.444799  -0.127534 -0.614585  -1.351955   \n",
       "5199 -0.617382  0.032498 -0.584724   1.441515  -0.131663 -1.055520  -1.355568   \n",
       "5200 -0.568890  0.032498 -0.569341   1.438009  -0.135421 -1.348203  -1.359425   \n",
       "5201 -0.566465  0.032498 -0.566974   1.437619  -0.135844 -1.367497  -1.359854   \n",
       "\n",
       "       R2-VCM1   R4-VCM1  R3-PA5:IH  ...  R2-PA4:IH  R3-PA4:IH  R1-PA5:IH  \\\n",
       "0     0.028357 -0.014322   0.632234  ...   1.636321   1.636498  -1.307082   \n",
       "1     0.025628 -0.089056   0.611412  ...   1.602650   1.602326  -1.328207   \n",
       "2     0.014827 -0.054766   0.610133  ...   1.598915   1.600499  -1.328912   \n",
       "3     0.008040 -0.153825   0.609098  ...   1.591954   1.593194  -1.330482   \n",
       "4     0.009062 -0.177378   0.607333  ...   1.587201   1.589305  -1.331999   \n",
       "...        ...       ...        ...  ...        ...        ...        ...   \n",
       "5197  0.030555 -0.013022   1.924613  ...  -0.815532  -0.854336  -0.072547   \n",
       "5198  0.019059 -0.013022   1.925709  ...  -0.822040  -0.854454  -0.078722   \n",
       "5199  0.016193 -0.061298   1.924369  ...  -0.849712  -0.855868  -0.106022   \n",
       "5200 -0.032542 -0.283365   1.909331  ...  -0.875573  -0.870125  -0.130614   \n",
       "5201 -0.036711 -0.283365   1.907444  ...  -0.876988  -0.871363  -0.131373   \n",
       "\n",
       "        R1-sI1  R2-PA2:VH  R1-PM2:V  R3-PA:ZH   R2-VCM2   R1-VCM2   R4-VCM2  \n",
       "0     1.382465  -1.318864 -0.212841  2.724037 -0.124961 -0.055162 -0.027867  \n",
       "1     0.727325  -1.336730 -0.140439 -0.446013 -0.145185 -0.065000 -0.029703  \n",
       "2     0.617168  -1.337346 -0.119145 -0.445742 -0.145577 -0.065091 -0.029708  \n",
       "3     0.417324  -1.337962 -0.072297 -0.437863 -0.145104 -0.065039 -0.029698  \n",
       "4     0.218662  -1.338732 -0.051002 -0.436334 -0.145753 -0.065393 -0.029765  \n",
       "...        ...        ...       ...       ...       ...       ...       ...  \n",
       "5197  1.631611  -0.169837  0.106578 -0.430800  0.159554  0.080392 -0.005228  \n",
       "5198  1.623928  -0.170967  0.110836 -0.431232  0.153000  0.078757 -0.005356  \n",
       "5199  1.347340  -0.174612  0.153426 -0.427190  0.126257  0.067752 -0.005694  \n",
       "5200  0.341028  -0.178257  0.183238 -0.409488  0.103326  0.054063 -0.007536  \n",
       "5201  0.296863  -0.178616  0.183238 -0.407941  0.097264  0.053705 -0.007525  \n",
       "\n",
       "[5202 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_new, y, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 3.28 seconds\n",
      "Accuracy: 95.2%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# base_model = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clf_4= RandomForestClassifier(n_estimators=100, random_state=43)\n",
    "# create the AdaBoost classifier\n",
    "clf_ada_dt = AdaBoostClassifier(base_estimator=clf_4)\n",
    "\n",
    "# train the model using the training data\n",
    "clf_ada_dt.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing data\n",
    "y_pred = clf_ada_dt.predict(X_test)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed time: {:.2f} seconds\".format(elapsed_time))\n",
    "\n",
    "# evaluate the model's accuracy\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "model_precision.append(precision_score(y_test,y_pred,average='weighted'))\n",
    "model_recal.append(recall_score(y_test,y_pred,average='weighted'))\n",
    "model_f1.append(f1_score(y_test,y_pred,average='weighted'))\n",
    "print(f'Accuracy: {round(score*100,2)}%')\n",
    "model_acc.append(score)\n",
    "model_time.append(elapsed_time)\n",
    "model_nam.append(\"AdaBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy  Precision    Recall  f1_score  elapsed_time\n",
      "0  0.952015   0.955778  0.952015  0.952067      3.278566\n"
     ]
    }
   ],
   "source": [
    "data = {'Accuracy': model_acc, 'Precision': model_precision, 'Recall': model_recal, 'f1_score': model_f1, \"elapsed_time\": model_time}\n",
    "df1 = pd.DataFrame(data)\n",
    "print(df1)\n",
    "# df1.to_csv('final_mean_'+str(number)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     138\n",
      "2     110\n",
      "3     171\n",
      "4     235\n",
      "5     353\n",
      "6     197\n",
      "7      89\n",
      "8     144\n",
      "9      13\n",
      "10    181\n",
      "11    115\n",
      "12     77\n",
      "13     67\n",
      "14    126\n",
      "15     86\n",
      "16    138\n",
      "17     87\n",
      "18     40\n",
      "19    164\n",
      "20     42\n",
      "21    104\n",
      "22     74\n",
      "23    126\n",
      "24    169\n",
      "25     65\n",
      "26    130\n",
      "27     34\n",
      "28     40\n",
      "29    254\n",
      "30     65\n",
      "35    289\n",
      "36    332\n",
      "37    236\n",
      "38    134\n",
      "39     93\n",
      "40     81\n",
      "41    403\n",
      "Name: marker, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# For total dataset\n",
    "df_cm_total = y['marker'].value_counts().sort_index(ascending=True)\n",
    "print(df_cm_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     122\n",
      "2     103\n",
      "3     159\n",
      "4     218\n",
      "5     314\n",
      "6     171\n",
      "7      77\n",
      "8     130\n",
      "9      11\n",
      "10    164\n",
      "11    103\n",
      "12     71\n",
      "13     61\n",
      "14    111\n",
      "15     78\n",
      "16    125\n",
      "17     74\n",
      "18     34\n",
      "19    153\n",
      "20     36\n",
      "21     91\n",
      "22     66\n",
      "23    113\n",
      "24    147\n",
      "25     55\n",
      "26    123\n",
      "27     31\n",
      "28     36\n",
      "29    228\n",
      "30     61\n",
      "35    256\n",
      "36    293\n",
      "37    210\n",
      "38    124\n",
      "39     83\n",
      "40     74\n",
      "41    375\n",
      "Name: marker, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# For Train Set\n",
    "df_cm_train = y_train['marker'].value_counts().sort_index(ascending=True)\n",
    "print(df_cm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     16\n",
      "2      7\n",
      "3     12\n",
      "4     17\n",
      "5     39\n",
      "6     26\n",
      "7     12\n",
      "8     14\n",
      "9      2\n",
      "10    17\n",
      "11    12\n",
      "12     6\n",
      "13     6\n",
      "14    15\n",
      "15     8\n",
      "16    13\n",
      "17    13\n",
      "18     6\n",
      "19    11\n",
      "20     6\n",
      "21    13\n",
      "22     8\n",
      "23    13\n",
      "24    22\n",
      "25    10\n",
      "26     7\n",
      "27     3\n",
      "28     4\n",
      "29    26\n",
      "30     4\n",
      "35    33\n",
      "36    39\n",
      "37    26\n",
      "38    10\n",
      "39    10\n",
      "40     7\n",
      "41    28\n",
      "Name: marker, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# For test set\n",
    "df_cm_test = y_test['marker'].value_counts().sort_index(ascending=True)\n",
    "print(df_cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the confusion matrix with zeros\n",
    "cm = np.zeros((42, 42), dtype=int)\n",
    "\n",
    "# fill the confusion matrix with the actual counts\n",
    "for i in range(len(y_test)):\n",
    "    cm[y_test.iloc[i]['marker'], y_pred[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0, 15,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  7, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  9,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  6,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0, 28]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Class  TP  FP  FN   TN\n",
      "0       1  15   3   1  502\n",
      "1       2   7   0   0  514\n",
      "2       3  12   1   0  508\n",
      "3       4  17   2   0  502\n",
      "4       5  36   3   3  479\n",
      "5       6  25   0   1  495\n",
      "6       7   9   0   3  509\n",
      "7       8  14   0   0  507\n",
      "8       9   2   0   0  519\n",
      "9      10  16   2   1  502\n",
      "10     11  12   0   0  509\n",
      "11     12   5   0   1  515\n",
      "12     13   5   0   1  515\n",
      "13     14  14   0   1  506\n",
      "14     15   8   0   0  513\n",
      "15     16  13   2   0  506\n",
      "16     17  12   0   1  508\n",
      "17     18   6   0   0  515\n",
      "18     19  11   2   0  508\n",
      "19     20   6   0   0  515\n",
      "20     21  12   0   1  508\n",
      "21     22   7   0   1  513\n",
      "22     23  11   0   2  508\n",
      "23     24  21   0   1  499\n",
      "24     25   9   0   1  511\n",
      "25     26   6   1   1  513\n",
      "26     27   3   0   0  518\n",
      "27     28   4   0   0  517\n",
      "28     29  26   1   0  494\n",
      "29     30   4   1   0  516\n",
      "30     35  33   1   0  487\n",
      "31     36  37   1   2  481\n",
      "32     37  25   4   1  491\n",
      "33     38  10   0   0  511\n",
      "34     39   9   0   1  511\n",
      "35     40   6   1   1  513\n",
      "36     41  28   0   0  493\n"
     ]
    }
   ],
   "source": [
    "# get the number of classes\n",
    "n_classes = 42\n",
    "\n",
    "# initialize arrays to store the TP, FP, TN, and FN values\n",
    "TP = np.zeros(n_classes, dtype=int)\n",
    "FP = np.zeros(n_classes, dtype=int)\n",
    "TN = np.zeros(n_classes, dtype=int)\n",
    "FN = np.zeros(n_classes, dtype=int)\n",
    "\n",
    "# print('Class', 'TP', 'FP', 'FN', 'TN')\n",
    "# calculate the TP, FP, TN, and FN values for each class\n",
    "for i in y_test['marker'].sort_index(ascending=False).unique():\n",
    "    TP[i] = cm[i, i]\n",
    "    FP[i] = np.sum(cm[:, i]) - cm[i, i]\n",
    "    FN[i] = np.sum(cm[i, :]) - cm[i, i]\n",
    "    TN[i] = np.sum(cm) - TP[i] - FP[i] - FN[i]\n",
    "\n",
    "data_cm = {'Class' : range(0,42), 'TP' : TP, 'FP': FP, 'FN': FN, 'TN' : TN}\n",
    "df_cm = pd.DataFrame(data_cm)\n",
    "#     print(i,TP[i],FP[i],FN[i],TN[i])\n",
    "df_cm = df_cm.drop([0, 31,32,33,34]).reset_index(drop=True)\n",
    "print(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  496    25]\n",
      " [   25 18731]]\n"
     ]
    }
   ],
   "source": [
    "TCM = np.zeros((2,2), dtype=int)\n",
    "TTP = TP.sum()\n",
    "TFP = FP.sum()\n",
    "TFN = FN.sum()\n",
    "TTN = TN.sum()\n",
    "TCM[0,0] = TTP\n",
    "TCM[0,1] = TFP\n",
    "TCM[1,0] = TFN\n",
    "TCM[1,1] = TTN\n",
    "print(TCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Misclassified Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R1-PM5:I       R1-VCM1  R3-PM5:I  R1-PA1:VH  R4-PA2:VH    R3-sV3  \\\n",
      "0  -0.422201  4.022153e-02 -0.439176   0.459438  -1.066174  0.500983   \n",
      "1  -0.108213  3.249814e-02 -0.230913  -0.159661  -1.651756 -1.255278   \n",
      "2   0.476118 -4.272086e-02  0.442394   1.800986   0.208407  0.978399   \n",
      "3   0.365798 -7.562933e-02  0.367845  -0.767073   1.096746 -1.425442   \n",
      "4   0.397318 -1.136068e-01 -0.488875  -0.902647   1.157596 -0.751528   \n",
      "5   0.445811  3.494169e-02  0.281463  -0.475110   1.374301  0.631271   \n",
      "6   0.478543  3.249814e-02  0.454227  -1.310148   0.576605 -1.441776   \n",
      "7  -0.590711  3.995520e-02 -0.603657  -0.602057   1.250095 -1.393994   \n",
      "8   0.573103 -4.134493e-02  0.538242  -0.593709   1.256763  0.961966   \n",
      "9  -2.595866  3.254279e-16  1.448212  -0.432924   1.182074 -1.309134   \n",
      "10  1.603563 -1.342132e-01 -0.758671  -1.095211   0.885798 -1.439841   \n",
      "11 -2.595866  3.254279e-16  2.396048  -0.666783   0.801378 -1.051828   \n",
      "12 -2.456451  5.556531e-02  0.152482  -1.320555   0.649785  0.325292   \n",
      "13 -1.779984  1.017508e-02  1.303848  -0.058036  -1.482401 -0.082974   \n",
      "14 -2.595866  3.254279e-16  2.650461  -0.650755   0.777322  1.378469   \n",
      "15 -0.680422  4.132487e-02 -0.687672  -1.198950   0.682475 -0.437241   \n",
      "16  0.870118  8.055460e-02 -1.938437  -0.438990   1.342202 -1.440450   \n",
      "17 -0.692545 -3.404174e-02 -0.699505   0.548708  -0.982609 -0.719457   \n",
      "\n",
      "    R1-PA3:VH       R2-VCM1   R4-VCM1  R3-PA5:IH  ...  R1-PA5:IH    R1-sI1  \\\n",
      "0    1.411579  4.247315e-02  0.039105   0.828219  ...  -1.095936  0.188342   \n",
      "1    0.730142  5.545759e-02  0.136315   0.215363  ...  -1.695518 -0.980722   \n",
      "2   -0.960103  5.545759e-02  0.098533  -1.534556  ...   0.175271  1.557861   \n",
      "3    0.061992  5.545759e-02  0.093535  -0.511223  ...   1.092546 -1.433375   \n",
      "4   -0.118900 -6.005544e-01 -0.047811  -0.477250  ...   0.887955  1.221496   \n",
      "5    0.383177  5.545759e-02  0.100746  -0.113043  ...   1.403306 -2.087905   \n",
      "6   -0.535797  4.190066e-02  0.027529  -1.105265  ...   0.556394  1.617415   \n",
      "7    0.243435  4.487082e-02  0.049736  -0.337095  ...   1.277203 -0.041356   \n",
      "8    0.252682  5.545759e-02  0.099443  -0.332103  ...   1.242428  1.634316   \n",
      "9    0.429594 -1.566374e-15  0.327320  -0.458132  ...  -0.119510 -0.433843   \n",
      "10  -0.344801 -4.783427e-01 -0.003953  -1.416868  ...   1.029278  0.620980   \n",
      "11   0.172156  4.747052e-01  0.091161  -0.861121  ...  -0.119510 -0.433843   \n",
      "12  -0.547187  5.545759e-02  0.105527  -0.769065  ...   0.775286 -1.249800   \n",
      "13   0.842082  5.545759e-02  0.104519   0.481243  ...  -1.668489 -2.487428   \n",
      "14   0.189853  5.545759e-02  0.080651  -0.904653  ...  -0.119510 -0.433843   \n",
      "15  -0.413202  3.685646e-02  0.032952  -0.993787  ...   0.699126  0.710705   \n",
      "16   0.422796 -1.070180e-01  1.141566  -0.292163  ...   1.467549  1.488255   \n",
      "17   1.509619  5.545759e-02  0.098483   0.918570  ...  -0.999301 -0.877150   \n",
      "\n",
      "    R2-PA2:VH  R1-PM2:V  R3-PA:ZH       R2-VCM2       R1-VCM2   R4-VCM2  \\\n",
      "0   -1.120437  1.022243  2.694401  1.227255e-01  6.511416e-02 -0.005407   \n",
      "1   -1.721698  0.430255 -0.433026  1.818109e-02  1.636754e-02 -0.013320   \n",
      "2    0.148926  0.289711  2.705654 -8.846812e-02 -3.788047e-02 -0.024390   \n",
      "3    1.049565  0.417478  2.726979 -9.016117e-02 -3.858630e-02 -0.023638   \n",
      "4    0.884742 -3.117417  1.776468  6.873569e-02  1.413487e-01 -0.708407   \n",
      "5    1.325450  0.272675  2.654391 -7.989677e-02 -3.310642e-02 -0.022004   \n",
      "6    0.523039  1.077609  2.713282 -7.543488e-02 -3.103729e-02 -0.023568   \n",
      "7    1.225208  0.468585  2.694589  1.636095e-01  8.460378e-02 -0.001534   \n",
      "8    1.206196 -0.102109  2.707691 -1.105420e-01 -4.868800e-02 -0.026393   \n",
      "9    1.114315  1.571642 -0.384221  1.228739e-15  1.029374e-15 -0.034750   \n",
      "10   0.832154 -2.495616  0.268393  2.994541e-01  5.272313e-03 -0.136183   \n",
      "11   0.705567  0.558022 -0.451476  2.699765e+00  1.029374e-15 -0.041103   \n",
      "12   0.565001 -0.255430 -0.332894  1.495476e+01  1.306188e+01 -0.009886   \n",
      "13  -1.594038  0.046953  2.347987  1.276041e+00  6.579903e-01 -0.032396   \n",
      "14   0.670975  0.485620 -0.449919  2.706341e+00  1.029374e-15 -0.043003   \n",
      "15   0.652312  0.208791  2.706297  1.815797e-01  9.387733e-02  0.000184   \n",
      "16   1.344675  0.217309 -0.306921 -1.126122e-01 -5.142957e-02  0.097874   \n",
      "17  -1.030971  0.609129  2.688949  2.072391e-01  1.066292e-01  0.002715   \n",
      "\n",
      "    Actual Class  Predicted Class  \n",
      "0             22               16  \n",
      "1             24               19  \n",
      "2             10               40  \n",
      "3             26               10  \n",
      "4             12               30  \n",
      "5             25               37  \n",
      "6             37               16  \n",
      "7              7                1  \n",
      "8             40                5  \n",
      "9              7                1  \n",
      "10             7               35  \n",
      "11            23               37  \n",
      "12            36                5  \n",
      "13            36               10  \n",
      "14            23               37  \n",
      "15            39               26  \n",
      "16            21               37  \n",
      "17            17                1  \n",
      "\n",
      "[18 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = []\n",
    "y_act = []\n",
    "# Find the indices of the misclassified samples\n",
    "misclassified_indices = []\n",
    "for i in range(len(y_test)):\n",
    "    if y_test.iloc[i]['marker'] in [7,8,9,10,11,12,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,35,36,37,38,39,40]:\n",
    "        if y_test.iloc[i]['marker'] != y_pred[i]:\n",
    "            y_pred1.append(y_pred[i])\n",
    "            y_act.append(y_test.iloc[i]['marker'])\n",
    "            misclassified_indices.append(i)\n",
    "\n",
    "# Get the misclassified data from the test set\n",
    "misclassified_data = X_test.iloc[misclassified_indices]\n",
    "mis_df = pd.DataFrame(misclassified_data.reset_index(drop=True))\n",
    "mis_df['Actual Class'] = y_act\n",
    "mis_df['Predicted Class'] = y_pred1\n",
    "# print(misclassified_data.reset_index(drop=True))\n",
    "print(mis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9520153550863724"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (cm.diagonal().sum()) / cm.sum()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = (TTP + TTN) / (TTP + TTN + TFP + TFN )\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cm.diagonal().sum() , cm.sum())\n",
    "# print(TP.sum()+TN.sum(),FP.sum() + FN.sum(),TP.sum() + TN.sum() + FP.sum() + FN.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9520153550863724"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = TTP / (TTP + TFP)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9520153550863724"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = TTP / (TTP + TFN)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9520153550863724"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score = 2*(precision*recall) / (precision+recall)\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
