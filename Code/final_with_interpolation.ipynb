{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sklearn.feature_selection import mutual_info_classif as MIC\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "from sklearn.externals import six\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import _name_estimators\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number = int(get_ipython().user_ns['param'])\n",
    "number = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_acc=[]\n",
    "model_precision=[]\n",
    "model_recal=[]\n",
    "model_f1=[]\n",
    "model_nam=[]\n",
    "model_confusion=[]\n",
    "model_time=[]\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report,f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Dataset CSV/csv_result-data'+str(number)+' Sampled Scenarios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the operation to create the new feature\n",
    "df['R1-VCM1'] = (df['R1-PM1:V'] - df['R1-PM7:V']) / (df['R1-PM4:I'] - df['R1-PM10:I'])\n",
    "df['R3-sV1'] = np.sin(df['R3-PA1:VH'] - df['R3-PA7:VH'])\n",
    "df['R3-sV3'] = np.sin(df['R3-PA3:VH'] - df['R3-PA9:VH'])\n",
    "# df['R2-VCM2'] = (df['R2-PM2:V'] - df['R2-PM8:V']) / (df['R2-PM5:I'] - df['R2-PM11:I'])\n",
    "df['R2-VCM1'] = (df['R2-PM1:V'] - df['R2-PM7:V']) / (df['R2-PM4:I'] - df['R2-PM10:I'])\n",
    "df['R3-VCM1'] = (df['R3-PM1:V'] - df['R3-PM7:V']) / (df['R3-PM4:I'] - df['R3-PM10:I'])\n",
    "df['R4-sI1'] = np.sin(df['R4-PA4:IH'] - df['R4-PA10:IH'])\n",
    "df['R2-VCA4'] = df['R2-PA7:VH'] - df['R2-PA10:IH']\n",
    "df['R1-sI1'] = np.sin(df['R1-PA4:IH'] - df['R1-PA10:IH'])\n",
    "df['R4-VCM2'] = (df['R4-PM2:V'] - df['R4-PM8:V']) / (df['R4-PM5:I'] - df['R4-PM11:I'])\n",
    "df['R2-VCA1'] = np.sin(df['R2-PA1:VH'] - df['R2-PA4:IH'] - df['R2-PA7:VH'] - df['R2-PA10:IH'])\n",
    "df['R3-VCM2'] = (df['R3-PM2:V'] - df['R3-PM8:V']) / (df['R3-PM5:I'] - df['R3-PM11:I'])\n",
    "df['R1-VCA4'] = df['R1-PA7:VH'] - df['R1-PA10:IH']\n",
    "df['R1-VCM2'] = (df['R1-PM2:V'] - df['R1-PM8:V']) / (df['R1-PM5:I'] - df['R1-PM11:I'])\n",
    "df['R2-VCM2'] = (df['R2-PM2:V'] - df['R2-PM8:V']) / (df['R2-PM5:I'] - df['R2-PM11:I'])\n",
    "df['R4-VCA4'] = df['R4-PA7:VH'] - df['R4-PA10:IH']\n",
    "df['R4-VCM1'] = (df['R4-PM1:V'] - df['R4-PM7:V']) / (df['R4-PM4:I'] - df['R4-PM10:I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the marker to the last of the list\n",
    "cols = list(df.columns)\n",
    "cols.remove('marker')\n",
    "df = df[cols + ['marker']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3209"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace= True)\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Create an instance of the KNNImputer class\n",
    "imputer = KNNImputer(n_neighbors=1)\n",
    "\n",
    "# Fit the imputer on the data\n",
    "imputed_data = imputer.fit_transform(df)\n",
    "\n",
    "# Replace the missing values in the original dataframe\n",
    "df = pd.DataFrame(imputed_data, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print(df.isin([np.inf, -np.inf]).sum().sum(), df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_z_scaled = df.copy()\n",
    "for column in df_z_scaled.columns:\n",
    "#     print(df_z_scaled[column])\n",
    "    if (df_z_scaled[column].std() != 0) and (column != 'id') and (column != 'marker'):\n",
    "        df_z_scaled[column] = (df_z_scaled[column] -\n",
    "                           df_z_scaled[column].mean()) / df_z_scaled[column].std()     \n",
    "# print(df_z_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_z_scaled.iloc[:,1:-1]\n",
    "y = df_z_scaled.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the top 31 features\n",
    "top_n_feature_names = ['R1-PM5:I', 'R1-VCM1', 'R3-PM5:I', 'R1-PA1:VH', 'R4-PA2:VH', 'R3-sV3',\n",
    " 'R1-PA3:VH', 'R2-VCM1', 'R4-VCM1', 'R3-PA5:IH', 'R1-PA2:VH', 'R3-sV1',\n",
    " 'R2-PA5:IH', 'R2-PA3:VH', 'R2-PA6:IH', 'R2-PA1:VH', 'R3-VCM1', 'R4-PA5:IH',\n",
    " 'R2-VCA4', 'R3-PA6:IH', 'R4-PM2:V', 'R2-PA4:IH', 'R3-PA4:IH', 'R1-PA5:IH',\n",
    " 'R1-sI1', 'R2-PA2:VH', 'R1-PM2:V', 'R3-PA:ZH', 'R2-VCM2', 'R1-VCM2', 'R4-VCM2', 'R1-PM2:V']\n",
    "\n",
    "# Filter the original dataframe to only include the top n features\n",
    "X_top_n = X[top_n_feature_names].copy()\n",
    "\n",
    "X_new = X_top_n.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_new, y, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 3.08 seconds\n",
      "Accuracy: 95.2%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# base_model = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clf_4= RandomForestClassifier(n_estimators=100, random_state=43)\n",
    "# create the AdaBoost classifier\n",
    "clf_ada_dt = AdaBoostClassifier(base_estimator=clf_4)\n",
    "\n",
    "# train the model using the training data\n",
    "clf_ada_dt.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing data\n",
    "y_pred = clf_ada_dt.predict(X_test)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed time: {:.2f} seconds\".format(elapsed_time))\n",
    "\n",
    "# evaluate the model's accuracy\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "model_precision.append(precision_score(y_test,y_pred,average='weighted'))\n",
    "model_recal.append(recall_score(y_test,y_pred,average='weighted'))\n",
    "model_f1.append(f1_score(y_test,y_pred,average='weighted'))\n",
    "print(f'Accuracy: {round(score*100,2)}%')\n",
    "model_acc.append(score)\n",
    "model_time.append(elapsed_time)\n",
    "model_nam.append(\"AdaBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy  Precision    Recall  f1_score  elapsed_time\n",
      "0  0.952015   0.956807  0.952015  0.952237      3.084744\n"
     ]
    }
   ],
   "source": [
    "data = {'Accuracy': model_acc, 'Precision': model_precision, 'Recall': model_recal, 'f1_score': model_f1, \"elapsed_time\": model_time}\n",
    "df1 = pd.DataFrame(data)\n",
    "print(df1)\n",
    "# df1.to_csv('final_int_'+str(number)+'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
